{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert https://dspy-docs.vercel.app/docs/category/local-language-model-clients to PDF: wkhtmltopdf reported an error:\n",
      "Exit with code 1 due to network error: ContentNotFoundError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pdfkit\n",
    "import PyPDF2\n",
    "\n",
    "# Define start URL and base URL\n",
    "start_url = \"https://dspy-docs.vercel.app/docs/intro\"\n",
    "base_url = \"https://dspy-docs.vercel.app\"\n",
    "\n",
    "# Function to get all links within the website\n",
    "def get_all_links(start_url, base_url):\n",
    "    visited = set()\n",
    "    to_visit = [start_url]\n",
    "    links = []\n",
    "\n",
    "    while to_visit:\n",
    "        url = to_visit.pop(0)\n",
    "        if url in visited:\n",
    "            continue\n",
    "        visited.add(url)\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        links.append(url)\n",
    "        \n",
    "        for a_tag in soup.find_all('a', href=True):\n",
    "            link = a_tag['href']\n",
    "            if link.startswith('/'):\n",
    "                link = base_url + link\n",
    "            if link.startswith(base_url) and link not in visited:\n",
    "                to_visit.append(link)\n",
    "    \n",
    "    return links\n",
    "\n",
    "# Specify the path to wkhtmltopdf executable\n",
    "path_to_wkhtmltopdf = '/usr/bin/wkhtmltopdf'\n",
    "config = pdfkit.configuration(wkhtmltopdf=path_to_wkhtmltopdf)\n",
    "\n",
    "# Function to save HTML as PDF\n",
    "def save_html_as_pdf(url, output_path):\n",
    "    try:\n",
    "        pdfkit.from_url(url, output_path, configuration=config)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {url} to PDF: {e}\")\n",
    "\n",
    "# Function to merge multiple PDFs into one\n",
    "def merge_pdfs(pdf_list, output_path):\n",
    "    merger = PyPDF2.PdfMerger()\n",
    "\n",
    "    for pdf in pdf_list:\n",
    "        merger.append(pdf)\n",
    "\n",
    "    merger.write(output_path)\n",
    "    merger.close()\n",
    "\n",
    "# Get all links to be converted to PDFs\n",
    "links = get_all_links(start_url, base_url)\n",
    "\n",
    "# Create a directory to store PDF files\n",
    "if not os.path.exists('pdfs'):\n",
    "    os.mkdir('pdfs')\n",
    "\n",
    "# Convert each link to a PDF\n",
    "for idx, link in enumerate(links):\n",
    "    output_path = f'pdfs/page_{idx}.pdf'\n",
    "    save_html_as_pdf(link, output_path)\n",
    "\n",
    "# List of PDF files to be merged\n",
    "pdf_files = [f'pdfs/page_{idx}.pdf' for idx in range(len(links)) if os.path.exists(f'pdfs/page_{idx}.pdf')]\n",
    "\n",
    "# Merge all PDFs into a single file\n",
    "merge_pdfs(pdf_files, 'merged_documentation.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
